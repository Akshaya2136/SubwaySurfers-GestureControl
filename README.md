ğŸ® Hand Gesture Controlled Subway Surfers

Control Subway Surfers using your hand gestures through your webcam!
This project uses MediaPipe + OpenCV + Python + Pynput to detect your hand movements and trigger game actions like left, right, jump, and duck.

ğŸš€ Features

 ğŸ–ï¸ Real-time hand tracking

 ğŸ¯ Detects gestures for:

   Move Left

   Move Right

   Jump

   Duck

 ğŸ® Controls Subway Surfers through keyboard emulation

 ğŸ“· Simple webcam-based interface

 âš¡ Lightweight and fast (runs on CPU)
 
 ğŸ› ï¸ Technologies Used

Python

OpenCV

MediaPipe

Pynput

TensorFlow Lite (MediaPipe backend)

â–¶ï¸ How to Run

1ï¸âƒ£ Create and activate environment

conda create -n subway python=3.10 -y

conda activate subway

2ï¸âƒ£ Install requirements

pip install opencv-python mediapipe pynput

3ï¸âƒ£ Run the program

python gesture_subway.py

Your webcam will open â†’ show your hand â†’ start controlling the game.


ğŸ•¹ï¸ Gestures & Actions
| Gesture                             | Action     |
| ----------------------------------- | ---------- |
| Hand moves left                     | Move Left  |
| Hand moves right                    | Move Right |
| Full open palm                      | Jump       |
| pinky extended (hang loose)         | Duck       |

ğŸ§  How It Works

MediaPipe Hands detects 21 landmarks on your hand

Landmark positions determine:

Horizontal movement â†’ lane switching

Finger extension â†’ jump & duck

Pynput simulates keyboard presses

Your gestures control the Subway Surfers player in real time

ğŸ§§ Future Enhancements

Add swipe-like gestures

Add calibration mode

Improve gesture accuracy

Add support for other games

ğŸ¤ Contributions

Pull requests are welcome!

If you'd like to add custom gestures or improve accuracy, feel free to contribute.
